{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnjzW0-TPMvF"
   },
   "source": [
    "# __Training of a Neural Network for a classification toy problem.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ie13pHt3gyh8"
   },
   "source": [
    "#### We import standard libraries and the three classes of the tool box ToyNN (ToyPb, nD_data, ToyNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Look at the companion note or to the dedicated notebook for the description of the classes.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as nprd\n",
    "from matplotlib import pyplot as plt\n",
    "#from matplotlib import cm as cm\n",
    "from toyneuralnetwork import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Woacru-MVEgA"
   },
   "source": [
    "### We  start by choosing a problem ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = ToyPb(name = \"square\", bounds = (-1,1))\n",
    "pb.show_border()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we pick a set of training data and a set of test data that fit the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = 1000\n",
    "DATA = nD_data(n = ndata, pb = pb)\n",
    "\n",
    "ntest = 500\n",
    "TEST = nD_data(n = ntest, pb = pb, init_pred='yes')\n",
    "\n",
    "TEST.show_class()\n",
    "pb.show_border('k--')\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We  choose the number layers and the number of nodes by layer for the neural network (with the constaints of   two input nodes and one output node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CardNodes = (2, 4, 6, 4, 1)\n",
    "NN = ToyNN(card = CardNodes, coef_bounds=(-1,1,-1,1), chi=\"tanh\", grid=(-1,1,41))\n",
    "NN.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GafO0zXoJ6Cx"
   },
   "source": [
    "## ___Full Batch Method___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We optmize the coefficents of the neural network (stored in__ NN.W __and__ NN.Bias __) in order to impove its predictions. In practice, we optimize__\n",
    "$$\n",
    "\\dfrac1n\\sum_{\\text{i}=0}^{n-1}\\ell\\left(  y_i \\widehat f(X_i)    \\right),\n",
    "$$\n",
    "__where__ $n=\\text{DATA.n}$, $\\,\\ell=\\text{pb.loss}$, $y_i=\\text{DATA.Y[i]}$,  $X_i=\\text{DATA.X[i]}$ __and where the funcion $\\widehat f(X)=\\text{NN.output}(X)$.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We first implement the full gradient method with fixed step.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AmqPOT9eJ6DC"
   },
   "source": [
    "### _Parameters for the Full Gradient and initialization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdVT9w-hJ6DJ"
   },
   "outputs": [],
   "source": [
    "to = 1        # fixed step size of the gradient descent algorithm\n",
    "Nepoch = 200    # Number of epochs \n",
    "\n",
    "plot_period = 20\n",
    "\n",
    "NN = ToyNN(card = CardNodes, coef_bounds=(-1,1,-1,1), chi=\"tanh\", grid=(-1,1,41))\n",
    "\n",
    "cost  = NN.total_loss_and_prediction(pb=pb, DATA=TEST)\n",
    "title = \"Epoch: \" + str(0) + \", Cost: \" + str(cost)\n",
    "print(title)\n",
    "NN.show_pred()\n",
    "TEST.show_class(pred=\"ok\")\n",
    "pb.show_border('w--')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5l_mvC1OJ6Da"
   },
   "source": [
    "### _Full gradient Iterations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "N49qsCBGJ6Df",
    "outputId": "624cf45f-d914-45bf-c277-c73e96fa9773"
   },
   "outputs": [],
   "source": [
    "\n",
    "### Iterations (no sub_iterations)\n",
    "for epoch in range(1, Nepoch + 1):\n",
    "    ## Computation of the descent direction\n",
    "    # 0-initialization of the partial and total stored descent direction\n",
    "    Tot_Desc_W, Tot_Desc_Bias = [], []\n",
    "    N=NN.N\n",
    "    # 0-initialization of the descent vectors\n",
    "    NN.init_vector()\n",
    "    # computation and summation over the data of their contributions to the total descent   \n",
    "    for j in range(ndata):\n",
    "        Desc_W, Desc_Bias = NN.descent(X=DATA.X[j], y=DATA.Y[j], pb=pb, tau=to)\n",
    "        NN.add_to_vector(Desc_W, Desc_Bias)\n",
    "    NN.mult_vector(1/ndata)       # renormalization of the sum of descent vectors      \n",
    "        # Update of the parameters\n",
    "    NN.add_vector_to_coefs()\n",
    "\n",
    "\n",
    "#computation of the error (sum of test losses)\n",
    "    if epoch%plot_period==0:\n",
    "        cost = NN.total_loss_and_prediction(DATA=TEST, pb = pb)\n",
    "        title = \"Epoch: \" + str(epoch) + \", Cost: \" + str(cost)\n",
    "        print(title)\n",
    "        NN.show_pred()\n",
    "        TEST.show_class(pred=\"yes\")\n",
    "        pb.show_border('w--')\n",
    "        plt.show()\n",
    "    else:\n",
    "        cost  = NN.total_loss(DATA=TEST, pb=pb)\n",
    "        title = \"Epoch: \" + str(epoch) + \", Cost: \" + str(cost)\n",
    "        print(title)\n",
    "\n",
    "NN.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exexcice : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUlLlKU8ZynE"
   },
   "source": [
    "__1/ Implement the Stochastic Gradient Method with constant step.__\n",
    "\n",
    "\n",
    "__2/ Observe and comment the convergence properties with the full batch metod.__\n",
    "\n",
    "\n",
    "__3/ Implement the Stochastic Gradient Method with decreasing step sizes:__\n",
    "$$\\tau^k := \\dfrac{\\gamma \\tau^0}{\\gamma + k}.$$\n",
    "\n",
    "\n",
    "__4/ Do you observe an improvement? Do you find an empirical method for the choice $\\tau^0$ and $\\gamma$?__\n",
    "\n",
    "__5/ Try the ring problem__ pb = ToyPb(name = \"ring\", bounds = (-1,1)). __What is the behavior of the full batch method on this problem.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imJTqdW6d4Cx"
   },
   "source": [
    "### _Parameters for the Stochastic Gradient Method and for the Neural network_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIUZ5oiuej7x"
   },
   "outputs": [],
   "source": [
    "to = .01           # fixed step size of the gradient descent algorithm\n",
    "Nepoch = 200     # Number of epochs \n",
    "ndata=1000\n",
    "plot_period = 20\n",
    "\n",
    "CardNodes = (2, 4, 6, 4, 1)\n",
    "NN = ToyNN(card = CardNodes, coef_bounds=(-1,1,-1,1), chi=\"tanh\", grid=(-1,1,41))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcxR-jiaPMwm"
   },
   "source": [
    "### _Stochastic Gradient Iterations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPLETE HERE ...###"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "GafO0zXoJ6Cx",
    "5l_mvC1OJ6Da",
    "ZzS5-IzwaKn3",
    "89AjhkJ2aKoB"
   ],
   "name": "ToyNN_class.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
